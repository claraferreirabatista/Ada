## Glossário de Termos de Machine Learning

Machine Learning (Aprendizado de Máquina) é uma disciplina repleta de termos técnicos. Aqui estão alguns dos principais jargões e seus significados:

1. **Aprendizado Supervisionado**:
   - *Definição*: Um tipo de algoritmo de ML onde o modelo é treinado com um conjunto de dados que inclui exemplos de entrada e saída esperada.
   - *Exemplo*: Classificação de e-mails em spam ou não spam, com base em exemplos anteriores.

2. **Aprendizado Não Supervisionado**:
   - *Definição*: Um tipo de algoritmo de ML onde o modelo é treinado com um conjunto de dados que não possui saída esperada. O modelo encontra padrões nos dados por conta própria.
   - *Exemplo*: Agrupamento de consumidores com base em seus hábitos de compra.

3. **Aprendizado por Reforço**:
   - *Definição*: Um tipo de aprendizado onde um agente toma ações em um ambiente para maximizar uma recompensa ao longo do tempo.
   - *Exemplo*: Treinamento de um agente para jogar xadrez ou dirigir um carro autônomo.

4. **Feature (Característica)**:
   - *Definição*: Uma variável ou atributo em um conjunto de dados que é usado como entrada para um modelo de ML.
   - *Exemplo*: Em um conjunto de dados de imóveis, as features podem incluir preço, número de quartos, localização, etc.

5. **Overfitting**:
   - *Definição*: Quando um modelo se ajusta excessivamente aos dados de treinamento, perdendo a capacidade de generalização para dados novos.
   - *Exemplo*: Um modelo de regressão que se encaixa perfeitamente aos dados de treinamento, mas não faz previsões precisas em novos dados.

6. **Underfitting**:
   - *Definição*: Quando um modelo é muito simples para capturar a complexidade dos dados de treinamento.
   - *Exemplo*: Um modelo linear que não pode representar adequadamente uma relação não linear nos dados.

7. **Bias (Viés)**:
   - *Definição*: Erro sistemático que leva o modelo a previsões incorretas.
   - *Exemplo*: Um modelo que tende a subestimar o preço das casas em uma determinada região.

8. **Variance (Variância)**:
   - *Definição*: Sensibilidade do modelo a pequenas variações nos dados de treinamento.
   - *Exemplo*: Um modelo que muda drasticamente suas previsões quando novos dados de treinamento são adicionados.

9. **Treinamento (Training)**:
   - *Definição*: O processo de ajustar um modelo aos dados de treinamento para aprender padrões e fazer previsões.
   - *Exemplo*: Treinar um modelo de ML com um conjunto de dados de imagens para identificar gatos e cachorros.

10. **Validação Cruzada (Cross-Validation)**:
    - *Definição*: Uma técnica para avaliar o desempenho do modelo dividindo os dados em subconjuntos para treinamento e teste em várias iterações.
    - *Exemplo*: Utilizar validação cruzada k-fold para avaliar um modelo de regressão.

11. **Hiperparâmetros**:
    - *Definição*: Parâmetros do modelo que não são aprendidos durante o treinamento, mas são ajustados antes do treinamento.
    - *Exemplo*: Taxa de aprendizado em um algoritmo de gradiente descendente.

12. **Feature Engineering (Engenharia de Características)**:
    - *Definição*: O processo de criar ou selecionar as melhores features para treinar um modelo.
    - *Exemplo*: Converter texto em números ou criar novas features com base em dados existentes.

13. **Ensemble Learning**:
    - *Definição*: Uma técnica que combina vários modelos para melhorar o desempenho de previsões.
    - *Exemplo*: Random Forest, que combina várias árvores de decisão.

14. **Regularização**:
    - *Definição*: Técnicas usadas para evitar overfitting, adicionando penalidades aos coeficientes do modelo.
    - *Exemplo*: Regressão Ridge e Lasso.

15. **Acurácia**:
    - *Definição*: Uma métrica que mede a proporção de previsões corretas em relação ao total de previsões.
    - *Exemplo*: Um modelo de classificação que previu corretamente 90% das instâncias.


16. **Regressão**:
    - *Definição*: Um tipo de aprendizado de máquina usado para prever valores numéricos com base em dados anteriores.
    - *Exemplo*: Prever o preço de uma casa com base em características como tamanho, número de quartos e localização.

17. **Classificação**:
    - *Definição*: Um tipo de aprendizado de máquina usado para atribuir rótulos ou categorias a dados com base em características.
    - *Exemplo*: Classificar e-mails como spam ou não spam.

18. **Métricas de Avaliação**:
    - *Definição*: Medidas usadas para avaliar o desempenho de um modelo, como precisão, recall, F1-score, e área sob a curva ROC.
    - *Exemplo*: Calcular a precisão de um modelo de classificação.

19. **SVM (Support Vector Machine)**:
    - *Definição*: Um algoritmo de aprendizado de máquina usado para classificação e regressão, que encontra um hiperplano de separação ótimo entre classes.
    - *Exemplo*: Classificar documentos em categorias com base em seu conteúdo.

20. **K-Means**:
    - *Definição*: Um algoritmo de agrupamento que divide os dados em clusters com base na proximidade.
    - *Exemplo*: Agrupar consumidores em grupos de acordo com suas preferências de compra.

21. **Rede Neural**:
    - *Definição*: Um modelo de aprendizado profundo inspirado no funcionamento do cérebro humano, com camadas de neurônios artificiais.
    - *Exemplo*: Redes neurais profundas são usadas em reconhecimento de imagem e processamento de linguagem natural.

22. **Gradient Descent (Descida de Gradiente)**:
    - *Definição*: Um algoritmo de otimização usado para ajustar os parâmetros de um modelo, minimizando uma função de perda.
    - *Exemplo*: Treinar um modelo de regressão linear com descida de gradiente.

23. **Data Preprocessing (Pré-processamento de Dados)**:
    - *Definição*: O conjunto de tarefas que envolvem a limpeza, transformação e preparação dos dados antes de alimentá-los em um modelo de machine learning.
    - *Exemplo*: Normalizar dados, tratar valores ausentes e codificar variáveis categóricas.

24. **Under-sampling e Over-sampling**:
    - *Definição*: Técnicas usadas para lidar com desequilíbrio de classes em problemas de classificação.
    - *Exemplo*: Subamostragem de instâncias da classe majoritária ou superamostragem da classe minoritária.

25. **Aprendizado Não Linear**:
    - *Definição*: Modelos de machine learning que não se limitam a relações lineares entre as features e a variável de saída.
    - *Exemplo*: Redes neurais, árvores de decisão.

26. **Validação Fora da Amostra**:
    - *Definição*: Avaliar o desempenho de um modelo em um conjunto de dados que não foi usado durante o treinamento.
    - *Exemplo*: Usar um conjunto de teste separado para verificar a capacidade de generalização do modelo.

27. **Deep Learning**:
    - *Definição*: Uma subárea do aprendizado de máquina que se concentra em redes neurais profundas com muitas camadas ocultas.
    - *Exemplo*: Redes neurais profundas usadas em reconhecimento de voz e visão computacional.


28. **Overhead**:
    - *Definição*: Os custos extras ou recursos necessários para executar um algoritmo ou processo, que não estão diretamente relacionados à tarefa principal.
    - *Exemplo*: Tempo gasto na preparação de dados antes de treinar um modelo.

29. **Batch Size**:
    - *Definição*: O número de exemplos de treinamento usados em uma única iteração de treinamento de um modelo de aprendizado de máquina.
    - *Exemplo*: Treinar uma rede neural com um tamanho de lote de 32 significa que 32 exemplos são usados de cada vez para ajustar os pesos do modelo.

30. **Feature Extraction (Extração de Características)**:
    - *Definição*: O processo de transformar dados brutos em representações numéricas ou vetores de características, adequados para alimentar um modelo de machine learning.
    - *Exemplo*: Extrair características de texto, como contagem de palavras, para análise de sentimentos.

31. **One-Hot Encoding**:
    - *Definição*: Uma técnica de codificação que converte variáveis categóricas em vetores binários para que possam ser usadas em algoritmos de aprendizado de máquina.
    - *Exemplo*: Codificar cores como "vermelho," "verde," e "azul" em vetores binários [1,0,0], [0,1,0], e [0,0,1].

32. **Hyperparameter Tuning (Ajuste de Hiperparâmetros)**:
    - *Definição*: O processo de ajustar os hiperparâmetros de um modelo para otimizar seu desempenho.
    - *Exemplo*: Experimentar diferentes taxas de aprendizado para encontrar a mais adequada.

33. **Regularização L1 e L2**:
    - *Definição*: Técnicas de regularização que adicionam penalidades aos coeficientes do modelo para evitar overfitting. L1 adiciona penalidades de valor absoluto, e L2 adiciona penalidades de valor quadrado.
    - *Exemplo*: Regressão Lasso (L1) e Regressão Ridge (L2).

34. **Random Forest**:
    - *Definição*: Um algoritmo de aprendizado de máquina baseado em árvores de decisão que combina várias árvores para melhorar a precisão e evitar overfitting.
    - *Exemplo*: Classificar se um e-mail é spam ou não com um modelo Random Forest.

35. **Gradient Boosting**:
    - *Definição*: Uma técnica de aprendizado de máquina que constrói um modelo de conjunto (ensemble) combinando múltiplos modelos fracos.
    - *Exemplo*: XGBoost, LightGBM.

36. **Cross-Entropy Loss (Entropia Cruzada)**:
    - *Definição*: Uma função de perda usada em problemas de classificação que mede a dissimilaridade entre as previsões do modelo e os rótulos reais.
    - *Exemplo*: Usado no treinamento de redes neurais para classificação.

37. **Regressão Logística**:
    - *Definição*: Um algoritmo de aprendizado de máquina usado para problemas de classificação binária, que modela a probabilidade de pertencer a uma classe.
    - *Exemplo*: Prever se um cliente fará ou não uma compra online.

38. **Recall e Precisão**:
    - *Definição*: Métricas de avaliação usadas em problemas de classificação. Recall mede a capacidade do modelo de encontrar todos os exemplos positivos, enquanto a precisão mede a proporção de exemplos positivos corretamente identificados.
    - *Exemplo*: Em um sistema de detecção de fraudes, é importante maximizar o recall para capturar a maioria das transações fraudulentas.

